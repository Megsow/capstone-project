{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927b266e",
   "metadata": {},
   "source": [
    "# Final work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1754373",
   "metadata": {},
   "source": [
    "# Setup the learning environment\n",
    "\n",
    "To begin, we import some library modules and functions that we will use.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "556fe0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "from imutils import perspective\n",
    "from imutils import contours\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import time\n",
    "from math import sqrt\n",
    "from tkinter import filedialog\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot as plt\n",
    "from rembg import remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f27ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(ptA, ptB):\n",
    "\treturn ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n",
    "#def mesureheight(image);\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb32d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Detected :  1\n"
     ]
    }
   ],
   "source": [
    "alg = \"haarcascade_frontalface_default.xml\"\n",
    "haar_cascade = cv2.CascadeClassifier(alg)\n",
    "\n",
    "# Reading the Image\n",
    "image = cv2.imread('people4.jpg')\n",
    "#Take out Backgroung\n",
    "image = remove(image)\n",
    "image = imutils.resize(image, width = min(800, image.shape[1])) \n",
    "\n",
    "grayImg = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "face = haar_cascade.detectMultiScale(grayImg,1.3,4)\n",
    "\n",
    "\n",
    "# getting no. of human detected\n",
    "print('Human Detected : ', len(face))\n",
    "Height = 0\n",
    "\n",
    "# loop over all detected humans\n",
    "for (x, y, w, h) in face:\n",
    "    pad_w, pad_h = int(0.5 * w), int(0.1 * h)\n",
    "    #cv2.rectangle(image, (x - pad_w, y - pad_h), (x + w + pad_w, 750 + y + h + pad_h), (0, 255, 0), 20)\n",
    "    pt1 = (12,y - pad_h)\n",
    "    pt2 = (12,700 + y + h - pad_h)\n",
    "    color = (255, 0, 0)\n",
    "\n",
    "    thickness=20\n",
    "\n",
    "    \n",
    "    #pt1 = (((x + pad_w) + (x + w - pad_w))/2, y + pad_h)\n",
    "    #pt2 = (x + w - pad_w, y + h - pad_h) \n",
    "    cv2.line(image, pt1, pt2,color,thickness)\n",
    "\n",
    "    # convert it to grayscale, and blur it slightly\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    # perform edge detection, then perform a dilation + erosion to\n",
    "    # close gaps in between object edges\n",
    "    edged = cv2.Canny(gray, 5, 10)\n",
    "    edged = cv2.dilate(edged, None, iterations=1)\n",
    "    edged = cv2.erode(edged, None, iterations=1)\n",
    "    # find contours in the edge map\n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    # sort the contours from left-to-right and initialize the\n",
    "    # 'pixels per metric' calibration variable\n",
    "    (cnts, _) = contours.sort_contours(cnts)\n",
    "    pixelsPerMetric = None\n",
    "    # loop over the contours individually\n",
    "    \n",
    "    # show the output image\n",
    "    #cv2.imshow(\"Image\", gray)\n",
    "    #cv2.imshow(\"Image\", edged)\n",
    "    #cv2.imshow(\"Image\", image)\n",
    "    #cv2.waitKey(0)\n",
    "    # loop over the contours individually\n",
    "    for c in cnts:\n",
    "        # if the contour is not sufficiently large, ignore it\n",
    "        if cv2.contourArea(c) < 300:\n",
    "            continue\n",
    "        # compute the rotated bounding box of the contour\n",
    "        orig = image.copy()\n",
    "        box = cv2.minAreaRect(c)\n",
    "        box = cv2.cv.BoxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box)\n",
    "        box = np.array(box, dtype=\"int\")\n",
    "        # order the points in the contour such that they appear\n",
    "        # in top-left, top-right, bottom-right, and bottom-left\n",
    "        # order, then draw the outline of the rotated bounding\n",
    "        # box\n",
    "        box = perspective.order_points(box)\n",
    "        cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n",
    "        # loop over the original points and draw them\n",
    "        for (x, y) in box:\n",
    "            cv2.circle(orig, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "            # unpack the ordered bounding box, then compute the midpoint\n",
    "            # between the top-left and top-right coordinates, followed by\n",
    "            # the midpoint between bottom-left and bottom-right coordinates\n",
    "            (tl, tr, br, bl) = box\n",
    "            (tltrX, tltrY) = midpoint(tl, tr)\n",
    "            (blbrX, blbrY) = midpoint(bl, br)\n",
    "            # compute the midpoint between the top-left and top-right points,\n",
    "            # followed by the midpoint between the top-righ and bottom-right\n",
    "            (tlblX, tlblY) = midpoint(tl, bl)\n",
    "            (trbrX, trbrY) = midpoint(tr, br)\n",
    "            # draw the midpoints on the image\n",
    "            cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n",
    "            cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n",
    "            cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n",
    "            cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n",
    "            # draw lines between the midpoints\n",
    "            cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),\n",
    "                (255, 0, 255), 2)\n",
    "            cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),\n",
    "                (255, 0, 255), 2)\n",
    "            # compute the Euclidean distance between the midpoints\n",
    "            dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n",
    "            dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n",
    "            # if the pixels per metric has not been initialized, then\n",
    "            # compute it as the ratio of pixels to supplied metric\n",
    "            # (in this case, inches)\n",
    "            if pixelsPerMetric is None:\n",
    "                pixelsPerMetric = dB / 0.044\n",
    "                \n",
    "            # compute the size of the object\n",
    "            dimA = dA / pixelsPerMetric\n",
    "            dimB = dB / pixelsPerMetric\n",
    "            # draw the object sizes on the image\n",
    "            cv2.putText(orig, \"{:.2f}m\".format(dimA),\n",
    "                (int(tltrX - 15), int(tltrY + 10)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.65, (255, 255, 255), 2)\n",
    "            cv2.putText(orig, \"{:.2f}m\".format(dimB),\n",
    "                (int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.65, (255, 255, 255), 2)\n",
    "            # show the output image\n",
    "            cv2.imshow(\"Image\", orig)\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "        Height = \"{:.2f}m\".format(dimA)\n",
    "        print('Height : ', \"{:.2f}m\".format(dimA))\n",
    "    print (Height)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmicalculculate(height):\n",
    "    weight = input(\"How much do you weigh: \")\n",
    "    bmi = weight/(height**2)\n",
    "    print(bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e9eb34",
   "metadata": {},
   "source": [
    "### Create model that detects humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "121538e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = \"haarcascade_frontalface_default.xml\"\n",
    "haar_cascade = cv2.CascadeClassifier(alg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206baee4",
   "metadata": {},
   "source": [
    "#### Create a detect method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a294bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frame):\n",
    "    #Take out Backgroung\n",
    "    frame = remove(frame)\n",
    "    grayImg = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    face = haar_cascade.detectMultiScale(grayImg,1.3,4)    \n",
    "    person = 1\n",
    "    \n",
    "    # loop over all detected humans\n",
    "    for (x, y, w, h) in face:\n",
    "        pad_w, pad_h = int(0.5 * w), int(0.1 * h)\n",
    "        pt1 = (x - pad_w,y + pad_h)\n",
    "        pt2 = (x - pad_w,800 + pad_h)\n",
    "        color = (255, 0, 0)\n",
    "\n",
    "        thickness=40\n",
    "        cv2.line(image, pt1, pt2,color,thickness)\n",
    "        cv2.putText(frame, f'person {person}', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
    "        person += 1\n",
    "        \n",
    "    cv2.putText(frame, 'Status : Detecting ', (40,40), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.putText(frame, f'Total Persons : {person-1}', (40,70), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.imshow('output', frame)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a7f2d",
   "metadata": {},
   "source": [
    "### Create a method to choose the file path or human detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a014027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanDetector(args):\n",
    "    image_path = args[\"image\"]\n",
    "    if str(args[\"camera\"]) == 'true' : camera = True \n",
    "    else : camera = False\n",
    "    writer = None\n",
    "    if args['output'] is not None and image_path is None:\n",
    "        writer = cv2.VideoWriter(args['output'],cv2.VideoWriter_fourcc(*'MJPG'), 10, (600,600))\n",
    "    if camera:\n",
    "        print('[INFO] Opening Web Cam.')\n",
    "        detectByCamera(ouput_path,writer)\n",
    "    elif image_path is not None:\n",
    "        print('[INFO] Opening Image from path.')\n",
    "        detectByPathImage(image_path, args['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2836d78b",
   "metadata": {},
   "source": [
    "### Create method to detect through camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c61603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectByCamera(writer):   \n",
    "    video = cv2.VideoCapture(0)\n",
    "    print('Detecting people...')\n",
    "    while True:\n",
    "        check, frame = video.read()\n",
    "        frame = detect(frame)\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e838da32",
   "metadata": {},
   "source": [
    "### Create method to detect human from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03395a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectByPathImage(path, output_path):\n",
    "    image = cv2.imread(path)\n",
    "    #Take out Backgroung\n",
    "    image = remove(image)\n",
    "\n",
    "    image = imutils.resize(image, width = min(800, image.shape[1])) \n",
    "\n",
    "    result_image = detect(image)\n",
    "\n",
    "    if output_path is not None:\n",
    "        cv2.imwrite(output_path, result_image)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef3ac5a",
   "metadata": {},
   "source": [
    "### Create a BMI calculator fundtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded920ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmicalculculate(height,weight):\n",
    "    bmi = weight/(height**2)\n",
    "    print(bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69327537",
   "metadata": {},
   "source": [
    "### Create and argument passer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argsParser():\n",
    "    arg_parse = argparse.ArgumentParser()\n",
    "    arg_parse.add_argument(\"-i\", \"--image\", default=None, help=\"path to Image File \")\n",
    "    arg_parse.add_argument(\"-c\", \"--camera\", default=False, help=\"Set true if you want to use the camera.\")\n",
    "    arg_parse.add_argument(\"-o\", \"--output\", type=str, help=\"path to optional output video file\")\n",
    "    args = vars(arg_parse.parse_args())\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d828649",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71448ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    alg = \"haarcascade_frontalface_default.xml\"\n",
    "    haar_cascade = cv2.CascadeClassifier(alg)\n",
    "\n",
    "    args = argsParser()\n",
    "    humanDetector(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb91c74",
   "metadata": {},
   "source": [
    "# APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a88d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO   ] [Logger      ] Record log in /Users/excellencesowunmi/.kivy/logs/kivy_23-03-20_0.txt\n",
      "[INFO   ] [Kivy        ] v2.1.0\n",
      "[INFO   ] [Kivy        ] Installed at \"/Users/excellencesowunmi/opt/anaconda3/lib/python3.8/site-packages/kivy/__init__.py\"\n",
      "[INFO   ] [Python      ] v3.8.8 (default, Apr 13 2021, 12:59:45) \n",
      "[Clang 10.0.0 ]\n",
      "[INFO   ] [Python      ] Interpreter at \"/Users/excellencesowunmi/opt/anaconda3/bin/python\"\n",
      "[INFO   ] [Logger      ] Purge log fired. Processing...\n",
      "[INFO   ] [Logger      ] Purge finished!\n",
      "[INFO   ] [Factory     ] 189 symbols loaded\n",
      "[INFO   ] [Image       ] Providers: img_tex, img_imageio, img_dds, img_sdl2, img_pil (img_ffpyplayer ignored)\n",
      "[INFO   ] [Text        ] Provider: sdl2\n",
      "[INFO   ] [Window      ] Provider: sdl2\n",
      "[INFO   ] [GL          ] Using the \"OpenGL ES 2\" graphics system\n",
      "[INFO   ] [GL          ] Backend used <sdl2>\n",
      "[INFO   ] [GL          ] OpenGL version <b'2.1 Metal - 83'>\n",
      "[INFO   ] [GL          ] OpenGL vendor <b'Apple'>\n",
      "[INFO   ] [GL          ] OpenGL renderer <b'Apple M1'>\n",
      "[INFO   ] [GL          ] OpenGL parsed version: 2, 1\n",
      "[INFO   ] [GL          ] Shading version <b'1.20'>\n",
      "[INFO   ] [GL          ] Texture max size <16384>\n",
      "[INFO   ] [GL          ] Texture max units <16>\n",
      "[INFO   ] [Window      ] auto add sdl2 input provider\n",
      "[INFO   ] [Window      ] virtual keyboard not allowed, single mode, not docked\n"
     ]
    }
   ],
   "source": [
    "from kivy.app import App\n",
    "from kivy.uix.gridlayout import GridLayout\n",
    "from kivy.uix.label import Label\n",
    "from kivy.uix.image import Image\n",
    "from kivy.uix.button import Button\n",
    "from kivy.uix.textinput import TextInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ff599",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMICalculator(App):\n",
    "    def build(self):\n",
    "        self.window = GridLayout()\n",
    "    return self.window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb83cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    alg = \"haarcascade_frontalface_default.xml\"\n",
    "    haar_cascade = cv2.CascadeClassifier(alg)\n",
    "\n",
    "    args = argsParser()\n",
    "    humanDetector(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4643189",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.window.cols = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c74864",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.window.add_widget(Image(source(\"logo_image.png\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.ageRequest = Label(text = \"Enter your year of birth...\")\n",
    "self.window.add_widget(self.ageRequest)\n",
    "\n",
    "self.date = TextInput(multiline=False)\n",
    "self.window.add_widget(self.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dda1a8",
   "metadata": {},
   "source": [
    "# Rough work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b039c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "alg = \"haarcascade_frontalface_default.xml\"\n",
    "haar_cascade = cv2.CascadeClassifier(alg)\n",
    "\n",
    "# Reading the Image\n",
    "image = cv2.imread('people4.jpg')\n",
    "#image = imutils.resize(image, width = min(800, image.shape[1])) \n",
    "\n",
    "grayImg = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "face = haar_cascade.detectMultiScale(grayImg,1.3,4)\n",
    "\n",
    "\n",
    "# getting no. of human detected\n",
    "print('Human Detected : ', len(face))\n",
    "\n",
    "# loop over all detected humans\n",
    "for (x, y, w, h) in face:\n",
    "    pad_w, pad_h = int(0.5 * w), int(0.1 * h)\n",
    "#    cv2.rectangle(image, (x + pad_w, y + pad_h), (x + w - pad_w, y + h - pad_h, (0, 255, 0), 2)\n",
    "    pt1 = (x + pad_w,y + pad_h)\n",
    "    pt2 = (x + pad_w,800 + pad_h)\n",
    "    color = (255, 0, 0)\n",
    "\n",
    "    thickness=20\n",
    "\n",
    "    \n",
    "    #pt1 = (((x + pad_w) + (x + w - pad_w))/2, y + pad_h)\n",
    "    #pt2 = (x + w - pad_w, y + h - pad_h) \n",
    "    cv2.line(image, pt1, pt2,color,thickness)\n",
    "\n",
    "\n",
    "x1 = [300, 300]\n",
    "y1 = [0, 900]\n",
    "#x2 = [200, 400]\n",
    "#y2 = [400, 400]\n",
    "#plt.plot(x1, y1, x2, y2, color=\"white\", linewidth=3)\n",
    "plt.plot(x1, y1, color=\"white\", linewidth=3)\n",
    "\n",
    "#plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "#plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "plt.imshow(cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)[1])\n",
    "plt.show()\n",
    "\n",
    "# display the output image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f166f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928805dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "alg = \"haarcascade_frontalface_default.xml\"\n",
    "haar_cascade = cv2.CascadeClassifier(alg)\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,img = cam.read()\n",
    "    text=\"Face not detected\"\n",
    "    grayImg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    face = haar_cascade.detectMultiScale(grayImg,1.3,4)\n",
    "    for (x,y,w,h) in face:\n",
    "        text=\"Face Detected\"\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h), (0,255,0),2)\n",
    "    print(text)\n",
    "    image = cv2.putText(img, text, (50,50), cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow(\"Face Detection\", image)\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frame):\n",
    "    grayImg = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    face = haar_cascade.detectMultiScale(grayImg,1.3,4)    \n",
    "    person = 1\n",
    "    # loop over all detected humans\n",
    "    for (x, y, w, h) in face:\n",
    "        pad_w, pad_h = int(0.5 * w), int(0.1 * h)\n",
    "        pt1 = (x + pad_w,y + pad_h)\n",
    "        pt2 = (x + pad_w,800 + pad_h)\n",
    "        color = (255, 0, 0)\n",
    "\n",
    "        thickness=20\n",
    "        cv2.line(image, pt1, pt2,color,thickness)\n",
    "        cv2.putText(frame, f'person {person}', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
    "        person += 1\n",
    "        \n",
    "        \n",
    "    cv2.putText(frame, 'Status : Detecting ', (40,40), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.putText(frame, f'Total Persons : {person-1}', (40,70), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.imshow('output', frame)\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanDetector(args):\n",
    "    image_path = args[\"image\"]\n",
    "    video_path = args['video']\n",
    "    if str(args[\"camera\"]) == 'true' : camera = True \n",
    "    else : camera = False\n",
    "    writer = None\n",
    "    if args['output'] is not None and image_path is None:\n",
    "        writer = cv2.VideoWriter(args['output'],cv2.VideoWriter_fourcc(*'MJPG'), 10, (600,600))\n",
    "    if camera:\n",
    "        print('[INFO] Opening Web Cam.')\n",
    "        detectByCamera(ouput_path,writer)\n",
    "    elif video_path is not None:\n",
    "        print('[INFO] Opening Video from path.')\n",
    "        detectByPathVideo(video_path, writer)\n",
    "    elif image_path is not None:\n",
    "        print('[INFO] Opening Image from path.')\n",
    "        detectByPathImage(image_path, args['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f85200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectByPathImage(path, output_path):\n",
    "    image = cv2.imread(path)\n",
    "    image = imutils.resize(image, width = min(800, image.shape[1])) \n",
    "    image = np.array(image)\n",
    "    result_image = detect(image)\n",
    "    if output_path is not None:\n",
    "        cv2.imwrite(output_path, result_image)\n",
    "        x1 = [300, 300]\n",
    "        y1 = [0, 900]\n",
    "        x2 = [200, 400]\n",
    "        y2 = [400, 400]\n",
    "        plt.plot(x1, y1, x2, y2, color=\"white\", linewidth=3)\n",
    "        \n",
    "        #plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        #plt.show()\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "detectByPathImage('people1.jpg', 'output_file.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbde524e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c82b1405",
   "metadata": {},
   "source": [
    "### TRIED DIFFERENT HUMAN DETECTION SOFTWARE CAME OUT WITH A LOT OF ERRORS SO SETTLED FOR A FACE DETECTION SOFTWARE INSTEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e9eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the HOG descriptor\n",
    "#hog = cv2.HOGDescriptor()\n",
    "#hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "HOGCV = cv2.HOGDescriptor()\n",
    "HOGCV.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefd480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import cv2\n",
    "\n",
    "# Reading the Image\n",
    "image = cv2.imread('people6.jpg')\n",
    "image = imutils.resize(image, width = min(800, image.shape[1])) \n",
    "\n",
    "# To Grayscale\n",
    "#im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "#cv2.imwrite(\"grayscale.jpg\", im)\n",
    "\n",
    "# resizing for faster detection\n",
    "frame = cv2.resize(frame, (640, 480))\n",
    "# using a greyscale picture, also for faster detection\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "# To Black & White\n",
    "#im = cv2.threshold(im, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "#cv2.imwrite(\"black-white.jpg\", im)\n",
    "\n",
    "# initialize the HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "\n",
    "# detect humans in input image\n",
    "(humans, _) = hog.detectMultiScale(image, winStride=(4, 4),\n",
    "padding=(8, 8), scale=1.03)\n",
    "\n",
    "# getting no. of human detected\n",
    "print('Human Detected : ', len(humans))\n",
    "\n",
    "# loop over all detected humans\n",
    "for (x, y, w, h) in humans:\n",
    "    pad_w, pad_h = int(0.5 * w), int(0.1 * h)\n",
    "#    cv2.rectangle(image, (x + pad_w, y + pad_h), (x + w - pad_w, y + h - pad_h), (0, 255, 0), 2)\n",
    "    pt1 = (x + pad_w,y + pad_h)\n",
    "    pt2 = (x + pad_w,800 + pad_h)\n",
    "    color = (255, 0, 0)\n",
    "\n",
    "    thickness=20\n",
    "\n",
    "    \n",
    "    #pt1 = (((x + pad_w) + (x + w - pad_w))/2, y + pad_h)\n",
    "    #pt2 = (x + w - pad_w, y + h - pad_h) \n",
    "    cv2.line(image, pt1, pt2,color,thickness)\n",
    "\n",
    "\n",
    "x1 = [300, 300]\n",
    "y1 = [0, 900]\n",
    "#x2 = [200, 400]\n",
    "#y2 = [400, 400]\n",
    "#plt.plot(x1, y1, x2, y2, color=\"white\", linewidth=3)\n",
    "plt.plot(x1, y1, color=\"white\", linewidth=3)\n",
    "\n",
    "#plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "#plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "plt.imshow(cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)[1])\n",
    "plt.show()\n",
    "\n",
    "# display the output image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73d44f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import cv2\n",
    "\n",
    "# Reading the Image\n",
    "image = cv2.imread('people1.jpg')\n",
    "#image = imutils.resize(image, width = min(800, image.shape[1])) \n",
    "\n",
    "# initialize the HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "\n",
    "# resizing for faster detection\n",
    "frame = cv2.resize(image, (640, 480))\n",
    "# using a greyscale picture, also for faster detection\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# detect people in the image\n",
    "# returns the bounding boxes for the detected objects\n",
    "boxes, weights = hog.detectMultiScale(frame, winStride=(8,8) )\n",
    "\n",
    "boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "\n",
    "# getting no. of human detected\n",
    "print('Human Detected : ', len(boxes))\n",
    "\n",
    "for (xA, yA, xB, yB) in boxes:\n",
    "    # display the detected boxes in the colour picture\n",
    "    cv2.rectangle(frame, (xA, yA), (xB, yB),\n",
    "                      (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "x1 = [300, 300]\n",
    "y1 = [0, 900]\n",
    "#x2 = [200, 400]\n",
    "#y2 = [400, 400]\n",
    "#plt.plot(x1, y1, x2, y2, color=\"white\", linewidth=3)\n",
    "plt.plot(x1, y1, color=\"white\", linewidth=3)\n",
    "\n",
    "#plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "#plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "plt.imshow(cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)[1])\n",
    "plt.show()\n",
    "\n",
    "# display the output image\n",
    "cv2.imshow(\"Image\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frame):\n",
    "\n",
    "    bounding_box_cordinates, weights =  HOGCV.detectMultiScale(frame, winStride = (4, 4), padding = (8, 8), scale = 1.03)\n",
    "    \n",
    "    person = 1\n",
    "    for x,y,w,h in bounding_box_cordinates:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        pad_w, pad_h = int(0.15 * w) int(0.01 * h)\n",
    "        #cv2.rectangle(image, (x + pad_w, y + pad_h), (x + w - pad_w, y + h - pad_h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'person {person}', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
    "        person += 1\n",
    "    \n",
    "    cv2.putText(frame, 'Status : Detecting ', (40,40), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.putText(frame, f'Total Persons : {person-1}', (40,70), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.imshow('output', frame)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a757a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe14b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
